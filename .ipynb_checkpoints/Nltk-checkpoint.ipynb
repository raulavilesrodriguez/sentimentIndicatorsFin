{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41af29c7-4b2e-4f2d-8c4f-55befcdacf2a",
   "metadata": {},
   "source": [
    "# Fundamental Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01384fd0-902c-4cf9-8be2-9ceb3513686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from GoogleNews import GoogleNews\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from openbb import obb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8892574d-1ea6-4724-84fc-cea36e5cbc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\bravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the VADER lexicon for sentiment analysis\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3750b6c2-ef25-43be-9296-c9f1faa553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data):\n",
    "    output_dir = \"data\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get the date and actual hour\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    file_path = os.path.join(output_dir, f\"data_{timestamp}.csv\")\n",
    "    \n",
    "    # Save the DATA\n",
    "    data.to_csv(file_path, index=True)\n",
    "    print(f\"Data saved in: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92694dd7-84cb-4550-beb5-50c4f98f147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_feed(actif):\n",
    "    #date in format \"mm/dd/yyyy\"\n",
    "    time.sleep(30)\n",
    "    googlenews=GoogleNews()\n",
    "    googlenews.set_lang('en')\n",
    "    googlenews.set_period('7d')\n",
    "    #googlenews.set_time_range(start_date, end_date)\n",
    "    googlenews.set_encode('utf-8')\n",
    "    googlenews.search(actif)\n",
    "\n",
    "    # process\n",
    "    news_items = []\n",
    "    pages = 1\n",
    "    summary = []\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    neutral_count = 0\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        time.sleep(30)\n",
    "        print(f\"Raul Aviles the Goat Get news of {page} page :) ...\")\n",
    "        #googlenews.get_page(page)\n",
    "        news=googlenews.results()\n",
    "\n",
    "        # Initialize the sentiment analyzer\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        for entry in news:\n",
    "            title = entry['title']\n",
    "            desc = entry['desc']\n",
    "            information = f\"{title}. {desc}\"\n",
    "            sentiment=sid.polarity_scores(information)['compound']\n",
    "            \n",
    "            # Sentiment threshold\n",
    "            if sentiment > 0.05:\n",
    "                positive_count += 1\n",
    "            elif sentiment <= 0:\n",
    "                negative_count += 1\n",
    "            else:\n",
    "                neutral_count += 1\n",
    "        \n",
    "            news_items.append([entry['datetime'], information, sentiment])\n",
    "\n",
    "    df = pd.DataFrame(news_items, columns=['Fecha', 'Noticia', 'Sentiment_Polarity'])\n",
    "    df = df.set_index('Fecha')    \n",
    "    summary.append({\n",
    "        'Positive_Ratio': positive_count/len(news_items), \n",
    "        'Negative_Ratio': negative_count/len(news_items), \n",
    "        'Neutral_Ratio': neutral_count/len(news_items),\n",
    "        'Positive Count': positive_count,\n",
    "        'Negative Count': negative_count,\n",
    "        'Neutral Count': neutral_count,\n",
    "    })\n",
    "    \n",
    "    save_data(df)\n",
    "    \n",
    "    return summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d32c474-194d-4828-9849-6323c34da5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raul Aviles the Goat Get news of 1 page :) ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ne \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNvidia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 44\u001b[0m, in \u001b[0;36mfetch_feed\u001b[1;34m(actif)\u001b[0m\n\u001b[0;32m     40\u001b[0m             neutral_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m         news_items\u001b[38;5;241m.\u001b[39mappend([entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m], information, sentiment])\n\u001b[1;32m---> 44\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(news_items, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFecha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoticia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment_Polarity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     45\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFecha\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n\u001b[0;32m     46\u001b[0m summary\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive_Ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: positive_count\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(news_items), \n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative_Ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: negative_count\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(news_items), \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeutral Count\u001b[39m\u001b[38;5;124m'\u001b[39m: neutral_count,\n\u001b[0;32m     53\u001b[0m })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "ne = fetch_feed(\"Nvidia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751bb06-cedb-4d55-84a4-3c9de5a32d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
